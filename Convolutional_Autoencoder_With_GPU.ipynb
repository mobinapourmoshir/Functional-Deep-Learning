{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN41gbmQJ/22HVpxXD0EB+Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobinapourmoshir/Functional-Deep-Learning/blob/main/Convolutional_Autoencoder_With_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convolutional Autoencoder**\n",
        "\n",
        "To enable GPU, you need to change runtime type from Runtime section in the menu section above in colab!"
      ],
      "metadata": {
        "id": "NcpDQpUEfsMs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL3IzXykeheC",
        "outputId": "1d7dd191-cfdb-4843-ceda-a9d1fff59b2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF: 2.19.0\n",
            "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Wed Nov 12 19:14:32 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf, subprocess, sys\n",
        "print(\"TF:\", tf.__version__)\n",
        "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"Memory growth enabled.\")\n",
        "    except Exception as e:\n",
        "        print(\"Could not set memory growth:\", e)\n",
        "else:\n",
        "    print(\"No GPU detected by TF.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoBEIX-we4c2",
        "outputId": "cb056c1f-3c12-47ce-b60d-d859721be95a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory growth enabled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')  # optional speed boost"
      ],
      "metadata": {
        "id": "kFEV41U_e7Xc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Data\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test  = x_test.astype('float32') / 255.\n",
        "x_train_cnn = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test_cnn  = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Model\n",
        "inp = tf.keras.Input(shape=(28, 28, 1))\n",
        "x = tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same')(inp)\n",
        "x = tf.keras.layers.MaxPooling2D((2,2), padding='same')(x)\n",
        "x = tf.keras.layers.Conv2D(8, (3,3), activation='relu', padding='same')(x)\n",
        "enc = tf.keras.layers.MaxPooling2D((2,2), padding='same')(x)\n",
        "\n",
        "x = tf.keras.layers.Conv2D(8, (3,3), activation='relu', padding='same')(enc)\n",
        "x = tf.keras.layers.UpSampling2D((2,2))(x)\n",
        "x = tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same')(x)\n",
        "x = tf.keras.layers.UpSampling2D((2,2))(x)\n",
        "out = tf.keras.layers.Conv2D(1, (3,3), activation='sigmoid', padding='same', dtype='float32')(x)  # dtype only needed if using mixed precision\n",
        "\n",
        "model = tf.keras.Model(inp, out)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Training (will use GPU automatically if available)\n",
        "history = model.fit(\n",
        "    x_train_cnn, x_train_cnn,\n",
        "    epochs=10, batch_size=256, shuffle=True,\n",
        "    validation_data=(x_test_cnn, x_test_cnn), verbose=1\n",
        ")\n",
        "\n",
        "# Quick check that TF is really placing on GPU\n",
        "print(\"Logical devices:\", tf.config.list_logical_devices())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3pJQKjdejSE",
        "outputId": "7211eccb-1a92-4080-a1a8-d40388d75bd3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - loss: 0.4964 - val_loss: 0.2997\n",
            "Epoch 2/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2934 - val_loss: 0.2883\n",
            "Epoch 3/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2850 - val_loss: 0.2843\n",
            "Epoch 4/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2810 - val_loss: 0.2807\n",
            "Epoch 5/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2776 - val_loss: 0.2786\n",
            "Epoch 6/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2757 - val_loss: 0.2770\n",
            "Epoch 7/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2746 - val_loss: 0.2759\n",
            "Epoch 8/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2731 - val_loss: 0.2748\n",
            "Epoch 9/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.2723 - val_loss: 0.2739\n",
            "Epoch 10/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2720 - val_loss: 0.2735\n",
            "Logical devices: [LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    }
  ]
}